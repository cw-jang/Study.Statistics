
### ch7.04 분할표

분할표Contigency Table는 명목형Categorical 또눈 순서형Ordinal 데이터의 도수Frequency를 표 형태로
기록한 것이다. 분할표가 작성되면 카이 제곱 검정Chi Square Test으로 변수 간에 의존 관계가 있는지를
독립섬 검정으로, 도수가 특정 분포르 따르는지를 적합도 검정Goodness of Fit으로 살펴볼 수 있다.

### <Note> 명목형, 순서형 데이터
명목형 데이터는 가능한 값이 제한되어 있고 종종 고정되어 있는 변수를 의미한다. 예를 들면, 국가명, 혈액형 등이다.

순서형 데이터는 값의 순서를 숫자로 지정한 변수다. 예를 들어, 설문 조사에서 제품 만족도를 조사하면서
응답을 매우 만족, 보통, 불만족, 매우 불만족으로 받을 수 있다. 이들 응답은 각각 5~1에 해당하는 숫자값으로
저장할 수 있는데, 이때 큰 값은 더 큰 만족을 의미한다. 하지만 이 값들 간에 기례적 관계는 존재하지 않는다.
예를 들어, 5는 2보다 큰 값이므로 더 만족한다는 의미지만 2.5배 더 만족한다는 의미는 아니다.

분할표가 사용되는 한 가지 경우는 기계 학습으로 데이터의 양성Positive, 음성Negative을 예측할 때다.
예를 들어, 이메일 텍스트를 보고 해당 이메일이 스팸인지 아닌지를 예측하는 경우를 생각해보자.
이때 두 가지 변수는 예측값(모델로 스팸인지를 판단한 결과)과 실제 값(실제로 해당 이메일이 스팸인지 여부)이다.
이런 실험에서 분할표의 모양은 다음과 같다.

			예측 - 스팸		예측-스팸아님
실제 - 스팸		a			b	
실제 - 스팸 아님	c			d

표에서 a는 주어진 이메일이 실제로 스팸일 때 모델의 예측 결과도 스팸인 경우의 수다.
b는 실제로 스팸인데 예측은 스팸이 아니라고 된 경우다. c와 d도 유사하게 해석할 수 있다.


### 분할표 작성
분할표를 작성하는 함수에는 table(), xtabs()가 있다. (table은 7.2.3 최빈값 참조)

### xtabs: 포뮬러를 사용해 분할표를 작성한다.
xtabs( 
      formula, 	L1 ~ R1 + R2 + R3 형태의 포뮬러다. R1, R2, R3등은 분할표의 분류를
      		나타내느 ㄴ변수들이다. "~"의 왼쪽에 빈도를 나타내는 변수를 적을 수 있다.
      data	포뮬러를 적용할 데이터
)
반환 값은 분할표다.

다음은 table()을 사용해 주어진 벡터에서 a,b,c의 출현 횟수를 세는 간단한 예다.
table(c("a","b","b","b","c","c","d"))


xtabs()는 포뮬러를 사용해 데이터를 지정할 수 있다. 예를 들어, x,y라는 변수가 있고 (x,y)에 대한
도수가 num에 저장되어 있을 때, 이 데이터로부터 분할표를 만드는 포뮬러는 num ~ x + y다.
d <- data.frame(x=c("1", "2", "2", "1"),
		y=c("A", "B", "A", "B"),
		num=c(3, 5, 8, 7))
(xtabs(num ~ x + y, data=d))

만약 도수를 나타내는 컬럼이 따로 없고, 각 관찰 결과가 서로 다른 행으로 표현되어 있다면 
'~변수 + 변수 ...' 형태로 포뮬러를 작성한다. 다음 코드는 x값이 A 또는 B인 각 경우를 세는 예제를 보여준다.
(d2 <- data.frame(x=c("A", "A", "A", "B", "B")))
(xtabs(~ x, d2))

### 합, 비율의 계산
여러 변수가 있을 때 한 변수만을 기준으로 총계를 구하는 경우를 생각해보자. 예를 들어, 다음은 
변수 A,B에 대한 분할표다. 각 변수는 True, False 값을 가질 수 있다. 이 표에는 변수 B가 True, False인
경우의 합을 표시한 컬럼과, 변수 A가 True, False일 때 합을 표시한 총계 행(80과 110)이 표시되어 있다.
또, 전체 도수의 합 역시 표시되어 있다. 이러한 총계 컬럼 또는 행을 주변 합marginal sum이라 한다.
'주변'이란 데이터가 표시된 바깥쪽 행 또는 열에 값이 기록되기에 붙여진 이름이다.

		| 변수A=True	| 변수B=False		| 총계
변수B=True	| 30		| 70			| 100
변수B=False	| 50		| 40			| 90
총계		| 80		| 110			| 190

주변 합이 계산되고 나면 이를 기준으로 비율을 계산할 수 있다.

		| 변수A=True	| 변수A=False
변수B=True	| 0.3(=30/100)	| 0.7(=70/100)
변수B=False	| 0.56(=50/90)	| 0.44(=40/90)


주변 합과 주변 비율은 margin.table(), prop.table()로 계산한다.
margin.table: 분할표의 주변 합을 구한다
margin.table(
	x, # 배열
	# 색인 번호, 1은 행 방향, 2는 열 방향을 뜻한다. 기본값인 NULL은 전체 값의 합을 구한다.
)
prop.table(
	x,
	margin=NULL
)

다음은 margin.table()을 사용해 행 방향, 열 방향의 합과 전체 합을 구한 예다.
d <- data.frame(x=c("1", "2", "2", "1"),
		y=c("A", "B", "A", "B"),
		num=c(3, 5, 8, 7))
(xt <- xtabs(num ~ x + y, data=d))
margin.table(xt,1) # 3 + 7 = 10, 8 + 5 = 13
margin.table(xt,2) # 3 + 8 = 11, 7 + 5 = 12
margin.table(xt) # 3 + 7 + 8 + 5 = 3

prop.table()은 분할표로부터 각 셀의 비율을 계산한다. 호출 형식은 margin.table()의 경우와 동일하다.
prop.table(xt, 1) # xt의 각 행을 각각 10(=3 + 7), 13(= 8 + 5)로 나눈 값
prop.table(xt, 2) # xt의 각 열을 각각 11(=3 + 8), 12(= 7 + 5)로 나눈 값
prop.table(xt) # xt의 각 셀을 전체 데이터의 합 23(=3 + 7 + 8 + 5)로 나눈 값


### 독립성 검정
분할표의 행에 나열된 변수와 열에 나열된 변수가 독립이라고 가정하자. 만약 분할표에서 
행과 열이 독립이라면 (i,j)셀의 확률 P(i,j)에 대해 다음 식이 성립한다.
P(i,j) = P(i) x P(j)


		| 변수A=True	| 변수A=False		| 총계
변수B=True	| 30		| 70			| 100
변수B=False	| 50		| 40			| 90
총계		| 80		| 110			| 190

표에서 변수A가 True일 확률은 80/190, 변수A가 False일 확률은 110/190이다. 마찬가지로
변수B가 True일 확률은 100/190, 변수B가 False일 확률은 90/190이다. 따라서 만약 A와 B가 독립이라면
변수A가 True이고, 변수B가 True일 확률은 (80/190) * (100/190) 이라고 할 수 있다. 
독립성 검정Independence Test은 실제로 이와 같은 가정이 성립하는지 알아보는 것을 목표로 한다.

<Note> 독립(Independence)
확률 이론에서 독립이란 두 사건이 서로 영향을 주고받지 않는 경우를 뜻한다. 반대로 독립이 아닌 경우는 
한 사건이 다른 사건에 영향을 주는 경우를 뜻한다.
예) 동전던지기에서 앞면/뒷면이 나올 확률은 독립이다.
(티스토리에 게제된 "Fisher의 정확한 검정" http://dermabe.tistory.com/175)

이를 일반화해서 표현해보자. 두 변서 A,B가 있을 때 A, B가 독립이면 P(A,B) = P(A)xP(B)가 성립한다.
반대로 독립이 아닌 예로는 항아리에서 구슬을 꺼내는 경우를 생각할 수 있다.

변수 간의 독립성 검정에는 카이 제곱 검정Chi-Squared Test을 사용한다.

library(MASS)
data(survey)
str(survey)
head(survey[c("Sex","Exer")])


성별과 운동이 독립인지를 확인해보기 위해 분할표를 만들어보자.
xtabs(~ Sex + Exer, data=survey)

분할표를 작성하고 나면 chisq.test()를 통해 카이 제곱 검정을 수행할 수 있다.
chisq.test: 카이 제곱 검정을 수행한다.
	x, # 숫자 벡터 또는 행렬. 또는 x와 y가 모두 팩터
	y=NULL, # 숫자 벡터 또는 x가 팩터인 경우 팩터로 지정. x가 행렬인 경우 그 안에 분할표가
		# 저장되어 있는 경우므로 y가 무시된다.
	# x와 같은 길이를 가질 확률. 이 값이 비율이 이 확률과 같은지를 테스트한다. 이 값이 지정되지
	# 않으면 확률이 서로 같은지 테스트한다. 이 인자는 7.5 적합도 검정에서 설명한다.
	p = rep(1/length(x), length(x))

chisq.test(xtabs(~ Sex + Exer, data=survey))

# Pearson's Chi-squared test
# 
# data:  xtabs(~Sex + Exer, data = survey)
# X-squared = 5.7184, df = 2, p-value = 0.05731
# 
# p 값이 0.05731이므로 0.05보다 커서 'H0: 성별과 운동은 독립이다.'라는 귀무가설을 기각할 수 없는 것으로
# 나타났다. 통계량 X^2은 5.7184였으며 자유도Degree of Freedom는 성별이 2개 레벨,
# 운동량이 3개 레벨이므로 (2-1)(3-1) = 2였다.

# <Note> 귀무가설, 대립가설, p-value, 유의수준
가설 검정에서 사용하는 귀무가설, 대립가설, p-value에 대해 알아보자.

통계에서의 가설 검정은 측정된 두 현상 간에 관련이 없다는 귀무가설(Null Hypotheis;흔히 H0으로 표시함)과 
두 현상간에 '관려이 있다'고 보는 것으로 연구자가 알아보고자 하는 대립가설(Alternative Hypothesis;흔히 H1으로 표시)을 사용한다. 귀무가설과 대립가설은 서로 모순 관계다. 따라서 귀무가설이 참이면 대립가설이 거짓이고, 
귀무가설이 거짓이면 대립가설이 참이다.

귀무가설은 '관련이 없다' 형태의 가설이다. 귀무가설의 예에는 
'두 변수가 독립이다', 
'두 변수의 평균에 차이가 없다'
'동전을 던졌을 때 앞면이 나올 확률과 뒷면이 나올 확률에 차이가 없다', 
'특정 약이 질병 치료에 효과가 없다', 
'올해 제품의 생산량과 작년의 생산량이 같다' 
등을 들 수 있다.

대립가설은 '관련이 있다'의 형태로 그 예로는 
'두 변수가 독립이 아니다' 
'두 변수의 평균에 차이가 있다'
'동전의 앞면이 나올 확률이 동전의 뒷면이 나올 확률과 다르다'
'특정 약이 질병 치료에 효과가 있다'
'올해 제품의 생산량과 작년의 생산량이 다르다'
등을 생각해 볼 수 있다.

대립가설은 값이 '같지 않다', '작다', '크다' 세 가지 형태로 나타낼 수 있다. 그 예로 '올해 생산량은 작년의 생산량과
다르다(즉, 올해 생산량이 크거나 작다)', '올해 생산량은 작년의 생산량보다 작다', '올해 생산량은 작년 생산량보다 크다'
를 들 수 있다. 이들 중 '같지않다'를 양측 검정(two sided test), '크다'와 '작다'를 단측 검정(one sided test)이라 한다.

가설 검정은 귀무가설을 일단 참이라고 가정하고 싲가한다. 그 뒤 귀무가설을 참이라고 생각했을 때 주어진 데이터 또는
그보다 극단적인 데이터가 관측될 확률을 구한다. 이를 p-value라고 한다. '더 극단적'이라는 개념은 대립가설의 형태마다
다르다. '크다'형태의 대립가설이라면 관측값 또는 그 값보다 큰 값을 볼 확률이 될 것이고, '작다'형태의 대립가설이면
관측값 또는 그보다 작은 값을 볼 확률이 된다. 반면 양측검정('같지않다'의 형태)의 경우에는 작은 경우와 큰 경우를
모두 포함한다.

예를 들어, 공장에서 올해의 생산량이 작년의 생산량보다 큰지를 알아보기 위해 전체 공장 100곳 중 10곳의 생산량을
조사해봤다고 하자. 이때 귀무가설(H0)은 '올해 생산량은 작년의 생산량과 같다'이고 대립가설(H1)은 '올해 생산량은
작년의 생산량보다 크다'이다. '크다'형태의 대립가설에서 p-value는 그림 7-4와 같다.

그림에서 곡선은 귀무가설이 참일 때(올해 생산량과 작년의 생산량이 같을 때) 10곳의 생산량이 어떻게 관찰되어야
하는지의 확률 분포를 나타낸다. 이 확률 분포는 작년의 생산량을 중심으로 서서히 작년의 생산량과 다른 값을 볼 
확률이 낮아지는 형태다. p-value는 조사 결과 알게 된 10곳의 생산량 또는 그보다 큰 생산량이 관찰될 확률로
색칠된 영역에 해당한다.

반면 대립가설을 'H1:올해의 생산량은 작년의 생산량과 다르다'로 놓으면 그림 7-5와 같이 반대쪽 영역을 
p-value 계산에 포함한다. 그 이유는 생산량이 같다는 귀무가설이 참이라고 할 때 '더 극단적'인 영역이란
작년의 생산량에 해당하는 가운데 부분에서 더 멀리 떨어지는 것을 의미하기 때문이다.

그림 7-4, 7-5에 보인 것처럼 궁극적으로 p-value는 귀무가설이 참일 때 주어진 데이터가 관찰될 확률이다.
따라서 p-value가 작다면 귀무가설이 참이라고 믿었는데 관찰된 데이터는 그 가정 하에서는 좀처럼
볼 수 없는 값이었다는 뜻이다. 따라서 p-value가 작다면 귀무가설이 사살이 아니라고 볼 수밖에 없으므로 
대립가설을 참이라고 판단한다. 이를 통계 용어로 '귀무가설을 기각(reject)하고 대립가설을 채택(accept)한다'
고 표현한다. 반대로 p-value가 크다면 귀무가설을 기각할 수 없으므로 대립가설을 기각하게 된다. 
즉 p-value는 귀무가설을 지지하는 정도다.

어느 정도의 p-value면 크다 또는 작다고 말할 수 있을까? p-value를 크다, 작다로 나누는 기준을 유의수준
(Significance Level) 이라고 하며 그 값을 기호 a로 표시한다. 유의수준으로는 보통 0.05가 사용된다. 즉
p-value가 5%보다 크다면 귀무가설을 채택한다. 이는 곧 귀무가설에 95%의 신뢰를 주는 것이다. 이처럼
귀무가설에 특혜를 주는 이유는 확실한 증거가 없이는 두 변수간에 상관관계가 있다고 말하지 않기 위함이다.
예를 들어, 어떤 새로운 약물이 질병에 효과가 있는지를 알아보는 가설 검정을 생각해보자. 약물이 적말로 
효과가 있는지 아주 잘 증명되지 않는다면 사람들은 투약을 꺼릴 것이다. 바로 이러한 점이 귀무가설을 
기준으로 모든 것을 생각하게 되는 이유다.

이 절에서 살펴본 성별과 운동의 데이터에 대한 독립성 검정에서 p-value는 0.05731이었다. 이 값은 0.05보다
커서 주어진 분할표는 성별과 운동이 상관관계가 없다는 귀무가설을 기각할 충분한 증거가 되지 않는다. 
따라서 성별과 운동은 상관관계가 없다는 결론을 내리게 된다.


### 피셔의 정확 검정
# 표본수가 적거나 표본이 분할표의 셀에 매우 치우치게 분포되어 있다면 카이 제곱 검정의 결과가 부정확할 수 있다.
# 대략, 기대빈도가 5이하인 셀이 전체의 20%이상인 경우 등이 이에 해당한다. 
# 이럴 경우 피셔의 정확 검정Fisher's Exact Test을 사용한다.
fisher.test(
	x, # 행렬 형태의 이차원 분할표 또는 팩터
	y=NULL, # 팩터. x가 행렬이면 무시
	alternative="two.sided" # 대립가설로 two.sided는 양측검정, less는 작다, greater는 크다를 의미

MASS::survey 데이터에서 손 글씨를 어느 손으로 쓰는지와 박수를 칠 때 어느 손이 위로 가는지
사이의 경우에 대해 피셔의 정확 검정을 수행해보자.
xtabs(~ W.Hnd + Clap, data=survey)
#        Clap
# W.Hnd   Left Neither Right
#   Left     9       5     4
#   Right   29      45   143

chisq.test(xtabs(~ W.Hnd + Clap, data=survey))
#         Pearson's Chi-squared test
# 
# data:  xtabs(~W.Hnd + Clap, data = survey)
# X-squared = 19.2524, df = 2, p-value = 6.598e-05
# 
# 경고메시지:
# In chisq.test(xtabs(~W.Hnd + Clap, data = survey)) :
#   카이제곱 approximation은 정확하지 않을수도 있습니다

이 경우 fisher.test()를 사용해야 한다.
fisher.test(xtabs(~ W.Hnd + Clap, data=survey)
#     	    Fisher's Exact Test for Count Data
# 
# data:  xtabs(~W.Hnd + Clap, data = survey)
# p-value = 0.0001413
# alternative hypothesis: two.sided)

### 맥니마 검정
벌금을 부과하기 시작한 후 안전벨트 착용자의 수, 선거 유세를 하고 난 뒤 지지율의 변화와 같이
응답자의 성향이 사건 전후에 어떻게 달라지는지를 알아보는 경우 맥니마 검정McNemar Test을 수행한다.
사건 전후에 응답자에게 설문을 하여 사건 발생 전 설문 결과를 Test1, 사건 발생 후 설문 결과를 Test2
라고 명시한 다음 표를 보자

			| Test2양성(Positive)	| Test2 음성(Negative)	| 총계
Test1 양성(Positive)	| a			| b			| a + b
Test1 음성(Negative)	| c			| d			| c + d
총계			| a + c			| b + d			| n


사건 전후에 설문 결과에 응답자 수 변화가 없다면 Test1의 positive와 Test2의 positive가 동일해야 하므로
a + b = a + c가 성립해야 한다. 또한, Test1의 negative와 Test2의 negative가 동일해야 하므로
c + d = b + d가 성립해야 한다. 이 둘을 정리해 결과적으로 b = c 여부를 검토하면 사건 전후에
성향 변화가 생겼는지 알 수 있다.

b = c가 성립하려면 b,c의 값이 b + c의 절반씩이 되어야 하므로 b는 이항분포를 따른다.
b ~ B(b + c, 1/2)

이항분포 B(n, p)에서 n이 크다면 이항 분포를 정규 분포로 근사할 수 있다.
b ~ N( (b+c)/2, (b+c)/4)

b를 표준화하여 N(0, 1)을 따르게 하고 연속성 수정Continuity Correction을 하면 다음이 성립한다.
(|b-c|-1)^2 / (b + c) ~ X^2(1)
